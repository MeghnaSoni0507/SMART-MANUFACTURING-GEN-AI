# ğŸ­ Smart Manufacturing GenAI Assistant

An end-to-end **AI-powered smart manufacturing platform** that predicts machine failures, explains risks, recommends actions, and enables what-if simulations â€” deployed as a **cloud-native containerized application**.

This project demonstrates **real-world AI engineering**, combining **machine learning, explainable AI, backend systems, Docker, and cloud deployment**.

---

## ğŸ¯ Problem Statement

Modern manufacturing systems generate massive sensor data, yet most predictive systems only show *risk scores* without explaining **why failures happen** or **what actions should be taken**.

This project solves that gap by providing:
- Predictive maintenance
- Explainability for predictions
- Actionable maintenance recommendations
- What-if simulations
- Cloud-deployed AI backend

---

## ğŸŒ Cloud Deployment (Docker + Azure Container Apps)

The backend of this project is deployed as a **containerized AI service** using **Docker and Azure Container Apps**.

### High-Level Architecture

React Frontend (Browser)
|
| HTTPS REST API
â†“
Azure Container Apps
(FastAPI + ML Inference Engine)
|
â†“
Trained ML Models (PyTorch / Scikit-learn)

markdown
Copy code

### Why this matters
- No local setup required for users
- Production-grade AI deployment
- Auto-scaling serverless containers
- Real-world DevOps + ML integration

---

## ğŸš€ Key Features

### ğŸ”® Predictive Maintenance
- ML models predict failure probability for machines
- Risk scores generated in real time

### ğŸ§  Explainable AI
- Feature-level explanation of predictions
- Highlights top contributing sensor parameters

### ğŸ› ï¸ Action Engine
- Rule-based + ML-driven maintenance recommendations
- Converts AI insights into **real operational actions**

### ğŸ” What-If Simulation
- Modify sensor inputs
- Instantly observe impact on failure risk

### ğŸŒ Cloud-Hosted AI API
- Backend deployed via Docker
- Public HTTPS endpoint
- Swagger API documentation enabled

---

## ğŸ§° Tech Stack

### Backend
- **Python 3.10**
- **FastAPI**
- **Gunicorn + Uvicorn**
- **PyTorch**
- **Scikit-learn**
- **Pandas / NumPy**
- **OpenAI API (GenAI-ready)**

### Frontend
- **React**
- **Vite**
- **Modern UI Components**

### DevOps & Cloud
- **Docker**
- **Azure Container Apps**
- **Docker Hub**
- **GitHub**

---

## ğŸ“ Project Structure

SMART-MANUFACTURING-GEN-AI/
â”‚
â”œâ”€â”€ Backend/
â”‚ â”œâ”€â”€ app/
â”‚ â”‚ â”œâ”€â”€ api/
â”‚ â”‚ â”œâ”€â”€ ml/
â”‚ â”‚ â””â”€â”€ services/
â”‚ â”œâ”€â”€ Dockerfile
â”‚ â”œâ”€â”€ .dockerignore
â”‚ â”œâ”€â”€ requirements.txt
â”‚ â””â”€â”€ requirements-runtime.txt
â”‚
â”œâ”€â”€ webapp/
â”‚ â”œâ”€â”€ src/
â”‚ â””â”€â”€ public/
â”‚
â””â”€â”€ README.md

yaml
Copy code

---

## ğŸ³ Dockerization Details

The backend is fully containerized for reproducible deployment.

### Key Files
Backend/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ requirements-runtime.txt

shell
Copy code

### Docker Image
meghna0507/sm-backend:latest

yaml
Copy code

### Container Configuration
- Runtime: Python 3.10
- Server: Gunicorn + Uvicorn
- Exposed Port: 8000
- CPU-only inference (cost efficient)

### Why Docker?
- Environment consistency
- Cloud portability
- Faster deployments
- No â€œworks on my machineâ€ issues

---

## â˜ï¸ Cloud Deployment (Recommended)

### Backend â€“ Azure Container Apps
- Serverless container execution
- Auto HTTPS & ingress
- Automatic scaling
- No Kubernetes configuration required

**API Endpoint:**
https://<azure-container-app-url>

markdown
Copy code

**Swagger Docs:**
https://<azure-container-app-url>/docs

yaml
Copy code

---

## ğŸ§ª Running Locally (Optional)

### Backend
```bash
cd Backend
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
uvicorn app.api.main:app --reload
Frontend
bash
Copy code
cd webapp
npm install
npm run dev
â˜ï¸ Why Azure Container Apps (Design Choice)
Azure Container Apps was chosen because it offers:

Serverless container hosting

Built-in HTTPS

Auto-scaling

Low-cost / free-tier friendly

Ideal for ML inference APIs

This allows focusing on AI logic instead of infrastructure management.

ğŸ§  Learning Outcomes
End-to-end AI system design

Explainable ML in production

Docker-based ML deployment

Cloud-native AI backend

Frontendâ€“backend integration

Real-world DevOps exposure

ğŸ“ Future Enhancements
SHAP-based deep explainability

Real-time sensor streaming

GenAI-powered maintenance chatbot

Multi-factory dashboard

Cost optimization with smaller base images

ğŸ‘©â€ğŸ’» Author
Meghna Soni
AI / ML Engineer | Smart Manufacturing | GenAI Systems

Built with PyTorch, FastAPI, React, Docker, and Azure Container Apps